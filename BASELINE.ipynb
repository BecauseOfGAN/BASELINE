{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "check.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:35:52.859822Z",
          "iopub.status.busy": "2021-08-24T03:35:52.859473Z",
          "iopub.status.idle": "2021-08-24T03:35:55.818094Z",
          "shell.execute_reply": "2021-08-24T03:35:55.817243Z",
          "shell.execute_reply.started": "2021-08-24T03:35:52.859748Z"
        },
        "id": "t6mkS2K2_9Lf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import torch\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "from glob import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL \n",
        "import urllib\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from random import uniform\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:35:55.819702Z",
          "iopub.status.busy": "2021-08-24T03:35:55.819404Z",
          "iopub.status.idle": "2021-08-24T03:35:55.825575Z",
          "shell.execute_reply": "2021-08-24T03:35:55.823356Z",
          "shell.execute_reply.started": "2021-08-24T03:35:55.819673Z"
        },
        "id": "GZ8g4tZL7F03"
      },
      "source": [
        "import torch.utils.data as td\n",
        "import torchvision as tv\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:35:55.828417Z",
          "iopub.status.busy": "2021-08-24T03:35:55.827801Z",
          "iopub.status.idle": "2021-08-24T03:35:55.835380Z",
          "shell.execute_reply": "2021-08-24T03:35:55.834563Z",
          "shell.execute_reply.started": "2021-08-24T03:35:55.828379Z"
        },
        "id": "tALkYOd_7MGH"
      },
      "source": [
        "!pip install pydicom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:35:55.837914Z",
          "iopub.status.busy": "2021-08-24T03:35:55.837607Z",
          "iopub.status.idle": "2021-08-24T03:35:56.040349Z",
          "shell.execute_reply": "2021-08-24T03:35:56.039542Z",
          "shell.execute_reply.started": "2021-08-24T03:35:55.837883Z"
        },
        "id": "uCqEeHYC7ISq"
      },
      "source": [
        "import pydicom as dcm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:35:56.041975Z",
          "iopub.status.busy": "2021-08-24T03:35:56.041600Z",
          "iopub.status.idle": "2021-08-24T03:35:56.045569Z",
          "shell.execute_reply": "2021-08-24T03:35:56.044657Z",
          "shell.execute_reply.started": "2021-08-24T03:35:56.041939Z"
        },
        "id": "V4c7UOjt7ybJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount._DEBUG = True\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:35:56.047072Z",
          "iopub.status.busy": "2021-08-24T03:35:56.046709Z",
          "iopub.status.idle": "2021-08-24T03:35:56.054590Z",
          "shell.execute_reply": "2021-08-24T03:35:56.053862Z",
          "shell.execute_reply.started": "2021-08-24T03:35:56.047039Z"
        },
        "id": "_0LeWnrf7pxM"
      },
      "source": [
        "os.chdir('./drive/MyDrive/body/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQG8RrO1RPN7"
      },
      "source": [
        "전처리\n",
        "\n",
        "\n",
        "*   https://github.com/tuvovan/Unet-with-EfficientnetB7-Backbone/blob/master/Body%20Morphometry.ipynb\n",
        "\n",
        "\n",
        "모델\n",
        "\n",
        "\n",
        "*   https://github.com/IanTaehoonYoo/semantic-segmentation-pytorch\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmiTRmsl9PzI",
        "tags": []
      },
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "    \n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hHSeU4ZSI22m"
      },
      "source": [
        "!pip install git+https://github.com/albumentations-team/albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1LTQymHI22n"
      },
      "source": [
        "!pip install --user albumentations==1.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyllcHvpI22o"
      },
      "source": [
        "import albumentations as A\n",
        "import albumentations.pytorch\n",
        "\n",
        "aug = A.Compose([\n",
        "                            A.HorizontalFlip(p=0.5,always_apply=False),\n",
        "                            A.OneOf([\n",
        "                                                                    A.RandomContrast(always_apply=False,p=0.2,limit=[-0.1,0.1]),\n",
        "                                                                    A.RandomGamma(always_apply=False,p=0.2,gamma_limit=[80,120]),\n",
        "                                                                    A.RandomBrightness(always_apply=False,p=0.2,limit=[-0.1,0.1])\n",
        "                                                                  ], p=0.3),\n",
        "                            A.OneOf([\n",
        "                                                                    A.ElasticTransform(always_apply=False,p=0.2,alpha=10,sigma=6.0,alpha_affine=1.5999999999999996,interpolation=1,border_mode=4,approximate=False),\n",
        "                                                                    A.GridDistortion(always_apply=False,p=0.2,num_steps=1,distort_limit=[-0.1,0.1],interpolation=1,border_mode=4),\n",
        "                                                                    #albumentations.augmentations.transforms.OpticalDistortion(always_apply=False,p=0.4,distort_limit=[-2,2],shift_limit=[-0.5,0.5],interpolation=1,border_mode=4),                 \n",
        "                                                                  ], p=0.3),\n",
        "                            #albumentations.augmentations.transforms.Cutout(always_apply=False,p=0.5,num_holes=8,max_h_size=50,max_w_size=50)\n",
        "                          #A.ShiftScaleRotate(always_apply=False,p=0.5,shift_limit=[-0.0625,0.0625],scale_limit=[-0.09999999999999998,0.12000000000000009],rotate_limit=[-25,25],interpolation=1,border_mode=4,value=None,mask_value=None),\n",
        "                          # albumentations.augmentations.transforms.Resize(always_apply=True,p=1,height=512,width=512,interpolation=1)\n",
        "\n",
        "                    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL4PsCAWIlot",
        "tags": []
      },
      "source": [
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "import pydicom\n",
        "\n",
        "def transform_to_hu(medical_image, image):\n",
        "    hu_image = image * medical_image.RescaleSlope + medical_image.RescaleIntercept\n",
        "    hu_image[hu_image < -1024] = -1024\n",
        "    return hu_image\n",
        "\n",
        "def window_image(image, window_center, window_width):\n",
        "    window_image = image.copy()\n",
        "    image_min = window_center - (window_width / 2)\n",
        "    image_max = window_center + (window_width / 2)\n",
        "    window_image[window_image < image_min] = image_min\n",
        "    window_image[window_image > image_max] = image_max\n",
        "    return window_image\n",
        "\n",
        "def resize_normalize(image):\n",
        "    image = np.array(image, dtype=np.float64)\n",
        "    image -= np.min(image)\n",
        "    image /= np.max(image)\n",
        "    return image\n",
        "\n",
        "def read_dicom(image_medical, window_widht, window_level):\n",
        "    image_data = image_medical.pixel_array\n",
        "\n",
        "    image_hu = transform_to_hu(image_medical, image_data)\n",
        "    image_window = window_image(image_hu.copy(), window_level, window_widht)\n",
        "    image_window_norm = resize_normalize(image_window)\n",
        "#     image_window_norm = image_window\n",
        "\n",
        "    image_window_norm = np.expand_dims(image_window_norm, axis=2)   # (512, 512, 1)\n",
        "    image_ths = np.concatenate([image_window_norm, image_window_norm, image_window_norm], axis=2)   # (512, 512, 3)\n",
        "    #print(image_window_norm.shape)\n",
        "    return image_ths\n",
        "\n",
        "def to_binary(img, lower, upper):\n",
        "    return (lower <= img) & (img <= upper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "QYRisXzBI22p"
      },
      "source": [
        "def mask_binarization(mask, threshold=None):\n",
        "    if threshold is None:\n",
        "        threshold = 0.5\n",
        "\n",
        "    if isinstance(mask, np.ndarray):\n",
        "        mask_binarized = (mask > threshold).astype(np.uint8)\n",
        "    \n",
        "    elif isinstance(mask, torch.Tensor):\n",
        "        zeros = torch.zeros_like(mask)\n",
        "        ones = torch.ones_like(mask)\n",
        "        \n",
        "        mask_binarized = torch.where(mask > threshold, ones, zeros)\n",
        "    \n",
        "    return mask_binarized\n",
        "\n",
        "def augment_imgs_and_masks(imgs, masks, rot_factor, scale_factor, trans_factor, flip):\n",
        "    rot_factor = uniform(-rot_factor, rot_factor)\n",
        "    ran_alp = uniform(10,100)\n",
        "    scale_factor = uniform(1-scale_factor, 1+scale_factor)\n",
        "    trans_factor = [int(imgs.shape[1]*uniform(-trans_factor, trans_factor)),\n",
        "                    int(imgs.shape[2]*uniform(-trans_factor, trans_factor))]\n",
        "\n",
        "    seq = iaa.Sequential([\n",
        "            iaa.Affine(\n",
        "                translate_px={\"x\": trans_factor[0], \"y\": trans_factor[1]},\n",
        "                scale=(scale_factor, scale_factor),\n",
        "                rotate=rot_factor\n",
        "            ),\n",
        "            #iaa.ElasticTransformation(alpha=ran_alp,sigma=5.0)\n",
        "        \n",
        "        ])\n",
        "\n",
        "    seq_det = seq.to_deterministic()\n",
        "\n",
        "    imgs = seq_det.augment_images(imgs)\n",
        "    masks = seq_det.augment_images(masks)\n",
        "\n",
        "    if flip and uniform(0, 1) > 0.5:\n",
        "        imgs = np.flip(imgs, 2).copy()\n",
        "        masks = np.flip(masks, 2).copy()\n",
        "    \n",
        "    masks = mask_binarization(masks).astype(np.float32)\n",
        "    return imgs, masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ARXf726QI22q"
      },
      "source": [
        "# Data augmentation\n",
        "rot_factor = 15 \n",
        "scale_factor = 0.15\n",
        "flip = True\n",
        "trans_factor = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:36:01.481257Z",
          "iopub.status.busy": "2021-08-24T03:36:01.480824Z",
          "iopub.status.idle": "2021-08-24T03:36:01.493406Z",
          "shell.execute_reply": "2021-08-24T03:36:01.492611Z",
          "shell.execute_reply.started": "2021-08-24T03:36:01.481224Z"
        },
        "id": "Ou_vStef7Kut"
      },
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_dir, y_dir,augmentation=False):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.augmentation = augmentation\n",
        "        self.x_img = x_dir\n",
        "        self.y_img = y_dir   \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_img = self.x_img[idx]\n",
        "        y_img = self.y_img[idx]\n",
        "        # Read an image with OpenCV\n",
        "        x_img = dcm.read_file(x_img)\n",
        "        y_img =  imread(y_img)\n",
        "\n",
        "        x_img=read_dicom(x_img,400,100)\n",
        "        x_img=np.transpose(x_img,(2,0,1))\n",
        "        x_img=x_img.astype(np.float32)\n",
        "\n",
        "        y_img = resize(y_img, (512, 512))*255\n",
        "        color_im = np.zeros([512, 512, 2])\n",
        "        for i in range(1,3):\n",
        "            encode_ = to_binary(y_img, i*1.0, i*1.0) * 255\n",
        "            color_im[:, :, i-1] = encode_\n",
        "        color_im = np.transpose(color_im,(2,0,1))\n",
        "        # Data Augmentation\n",
        "        if self.augmentation:\n",
        "            img, mask = augment_imgs_and_masks(x_img, color_im, rot_factor, scale_factor, trans_factor, flip)\n",
        "        \n",
        "        return x_img, color_im,y_img\n",
        "#         if self.transforms:\n",
        "#             augmented = self.transforms(image=x_img,mask=color_im)\n",
        "#             img = augmented['image']\n",
        "#             mask = augmented['mask']\n",
        "#             return img, mask,y_img\n",
        "# #         return x_img,color_im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:36:01.495131Z",
          "iopub.status.busy": "2021-08-24T03:36:01.494741Z",
          "iopub.status.idle": "2021-08-24T03:36:04.079144Z",
          "shell.execute_reply": "2021-08-24T03:36:04.078282Z",
          "shell.execute_reply.started": "2021-08-24T03:36:01.495093Z"
        },
        "id": "B7JE1IDH8iTl"
      },
      "source": [
        "import glob\n",
        "data_path=sorted(glob.glob( \"./train/DICOM/**/*.dcm\",recursive=True ))\n",
        "label_path=sorted(glob.glob(\"./train/Label/**/*.png\",recursive = True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:36:04.087731Z",
          "iopub.status.busy": "2021-08-24T03:36:04.087058Z",
          "iopub.status.idle": "2021-08-24T03:36:04.102613Z",
          "shell.execute_reply": "2021-08-24T03:36:04.101879Z",
          "shell.execute_reply.started": "2021-08-24T03:36:04.087692Z"
        },
        "id": "qhg9hfPv8qsU"
      },
      "source": [
        "data_path = pd.array(data_path)\n",
        "label_path = pd.array(label_path)\n",
        "\n",
        "train_input_files = data_path[1601:6300].to_numpy()\n",
        "train_label_files = label_path[1601:6300].to_numpy()\n",
        "\n",
        "val_input_files = data_path[:1600].to_numpy()\n",
        "val_label_files = label_path[:1600].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGeTyZVg5G3-"
      },
      "source": [
        "len(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:36:04.104785Z",
          "iopub.status.busy": "2021-08-24T03:36:04.104450Z",
          "iopub.status.idle": "2021-08-24T03:36:04.112043Z",
          "shell.execute_reply": "2021-08-24T03:36:04.111072Z",
          "shell.execute_reply.started": "2021-08-24T03:36:04.104750Z"
        },
        "id": "4isFVrb_8weM"
      },
      "source": [
        "train_dataset = MyDataset(train_input_files,train_label_files)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=16,shuffle=False)\n",
        "val_dataset = MyDataset(val_input_files,val_label_files)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=16,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:36:04.113817Z",
          "iopub.status.busy": "2021-08-24T03:36:04.113444Z",
          "iopub.status.idle": "2021-08-24T03:36:05.568248Z",
          "shell.execute_reply": "2021-08-24T03:36:05.567345Z",
          "shell.execute_reply.started": "2021-08-24T03:36:04.113782Z"
        },
        "id": "1MJmXHLz88_3",
        "scrolled": true
      },
      "source": [
        "##input과 label이 맞나 확인\n",
        "images,labels,a = next(iter(train_loader))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "plt.figure(figsize=(16,18))\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(images[0][0])\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(labels[0][0])\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(labels[0][1])\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(a[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:36:18.056248Z",
          "iopub.status.busy": "2021-08-24T03:36:18.055748Z",
          "iopub.status.idle": "2021-08-24T03:36:18.069724Z",
          "shell.execute_reply": "2021-08-24T03:36:18.068306Z",
          "shell.execute_reply.started": "2021-08-24T03:36:18.056206Z"
        },
        "id": "-RPu17l8trAm"
      },
      "source": [
        "def compute_per_channel_dice(input, target, epsilon=1e-5, ignore_index=None, weight=None):\n",
        "    # assumes that input is a normalized probability\n",
        "    # input and target shapes must match\n",
        "    assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
        "\n",
        "    # mask ignore_index if present\n",
        "    if ignore_index is not None:\n",
        "        mask = target.clone().ne_(ignore_index)\n",
        "        mask.requires_grad = False\n",
        "\n",
        "        input = input * mask\n",
        "        target = target * mask\n",
        "\n",
        "    input = flatten(input)\n",
        "    target = flatten(target)\n",
        "\n",
        "    # Compute per channel Dice Coefficient\n",
        "    intersect = (input * target).sum(-1)\n",
        "    if weight is not None:\n",
        "        intersect = weight * intersect\n",
        "\n",
        "    denominator = (input + target).sum(-1)\n",
        "    return 2. * intersect / denominator.clamp(min=epsilon)\n",
        "\n",
        "def flatten(tensor):\n",
        "    \"\"\"Flattens a given tensor such that the channel axis is first.\n",
        "    The shapes are transformed as follows:\n",
        "       (N, C, D, H, W) -> (C, N * D * H * W)\n",
        "    \"\"\"\n",
        "    C = tensor.size(1)\n",
        "    # new axis order\n",
        "    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n",
        "    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n",
        "    transposed = tensor.permute(axis_order).contiguous()\n",
        "    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n",
        "    return transposed.view(C, -1)\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Computes Dice Loss, which just 1 - DiceCoefficient described above.\n",
        "    Additionally allows per-class weights to be provided.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epsilon=1e-5, weight=None, ignore_index=None, sigmoid_normalization=True,\n",
        "                 skip_last_target=False):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        if isinstance(weight, list):\n",
        "            weight = torch.Tensor(weight)\n",
        "            \n",
        "        self.epsilon = epsilon\n",
        "        self.register_buffer('weight', weight)\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "        if sigmoid_normalization:\n",
        "            self.normalization = nn.Sigmoid()\n",
        "        else:\n",
        "            self.normalization = nn.Softmax(dim=1)\n",
        "        # if True skip the last channel in the target\n",
        "        self.skip_last_target = skip_last_target\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        # get probabilities from logits\n",
        "\n",
        "        input = self.normalization(input)\n",
        "        if self.weight is not None:\n",
        "            weight = Variable(self.weight, requires_grad=False).to(input.device)\n",
        "        else:\n",
        "            weight = None\n",
        "\n",
        "        if self.skip_last_target:\n",
        "            target = target[:, :-1, ...]\n",
        "\n",
        "        per_channel_dice = compute_per_channel_dice(input, target, epsilon=self.epsilon, ignore_index=self.ignore_index, weight=weight)\n",
        "        # Average the Dice score across all channels/classes\n",
        "        return torch.mean(1. - per_channel_dice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkmFcMoQ55jv"
      },
      "source": [
        "pip install git+https://github.com/qubvel/segmentation_models.pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:36:33.273326Z",
          "iopub.status.busy": "2021-08-24T03:36:33.273059Z",
          "iopub.status.idle": "2021-08-24T03:36:58.744557Z",
          "shell.execute_reply": "2021-08-24T03:36:58.743598Z",
          "shell.execute_reply.started": "2021-08-24T03:36:33.273297Z"
        },
        "id": "dPNj1z_LI22s"
      },
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "model = smp.FPN(  #DeepLabV3\n",
        "    encoder_name=\"resnet50\",# choose encoder, e.g. mobilenet_v2 or efficientnet-b7 resnext101_32x8d,timm-res2net101_26w_4s     # use `imagenet` pre-trained weights for encoder initialization \n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
        "    classes=2,                      # model output channels (number of classes in your dataset)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:36:58.748886Z",
          "iopub.status.busy": "2021-08-24T03:36:58.748613Z",
          "iopub.status.idle": "2021-08-24T03:36:58.759762Z",
          "shell.execute_reply": "2021-08-24T03:36:58.758916Z",
          "shell.execute_reply.started": "2021-08-24T03:36:58.748859Z"
        },
        "id": "Eb7basNdI22s"
      },
      "source": [
        "sum([param.nelement() for param in model.parameters()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "yeCbq_D5I22s"
      },
      "source": [
        "#model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiRaw4B39P1e",
        "tags": []
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion =  DiceLoss(sigmoid_normalization=True)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-8, momentum=0.9)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T07:47:55.376141Z",
          "iopub.status.busy": "2021-08-24T07:47:55.375749Z"
        },
        "id": "BxFM0Rno9xtV"
      },
      "source": [
        "n_epochs =100\n",
        "cnt =0\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "# keep track of training and validation loss\n",
        "train_loss = torch.zeros(n_epochs)\n",
        "valid_loss = torch.zeros(n_epochs)\n",
        "\n",
        "model.to(device)\n",
        "for e in range(0, n_epochs):\n",
        "\n",
        "   \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, labels,a in tqdm(train_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        data, labels = data.to(device), labels.to(device) #cpu에 있는 데이터를 gpu에 보냄\n",
        "        # clear the gradients of all optimized variables\n",
        "#         print(data.shape)\n",
        "#         break\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        logits = model(data)\n",
        "\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(logits, labels)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss[e] += loss.item()\n",
        "        \n",
        "        \n",
        "#         z=logits.detach().cpu().numpy()\n",
        "#         z = z.astype(np.uint8)\n",
        "        cnt = cnt+1\n",
        "        \n",
        "        \n",
        "        if cnt %10==0:\n",
        "            logits = logits.sigmoid()\n",
        "            logits = mask_binarization(logits.detach().cpu(), 0.5)\n",
        "            # y=torch.squeeze(labels[0])\n",
        "            y=logits[0].detach().cpu().numpy()\n",
        "            # x=data[0].detach().cpu().numpy()\n",
        "            x=labels[0].detach().cpu().numpy()\n",
        "            #y=labels[0].numpy()\n",
        "            plt.figure(figsize=(16,18))\n",
        "            plt.subplot(1,5,1)\n",
        "            plt.imshow(x[0])\n",
        "            plt.subplot(1,5,2)\n",
        "            plt.imshow(x[1])\n",
        "            plt.subplot(1,5,3)\n",
        "            plt.imshow(y[0])\n",
        "            plt.subplot(1,5,4)\n",
        "            plt.imshow(y[1])\n",
        "            plt.subplot(1,5,5)\n",
        "            plt.imshow(a[0])\n",
        "            plt.show()\n",
        "\n",
        "    \n",
        "    train_loss[e] /= len(train_loader)\n",
        "    #torch.save(model.state_dict(), 'model_.pt')\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    with torch.no_grad(): \n",
        "        model.eval()\n",
        "        for data, labels,a in tqdm(val_loader):\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            logits = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(logits, labels)\n",
        "            # update average validation loss \n",
        "            valid_loss[e] += loss.item()\n",
        "\n",
        "    \n",
        "    # calculate average losses\n",
        "    valid_loss[e] /= len(val_loader)\n",
        "    scheduler.step(valid_loss[e])    \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        e, train_loss[e], valid_loss[e]))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss[e] <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss[e]))\n",
        "        torch.save(model.state_dict(), 'model_best_2.pt')\n",
        "        valid_loss_min = valid_loss[e]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5pC9vPXQ30y"
      },
      "source": [
        "#Loss\n",
        "plt.plot(train_loss)\n",
        "plt.plot(valid_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T03:36:58.831992Z",
          "iopub.status.busy": "2021-08-24T03:36:58.831137Z",
          "iopub.status.idle": "2021-08-24T03:37:09.636526Z",
          "shell.execute_reply": "2021-08-24T03:37:09.635715Z",
          "shell.execute_reply.started": "2021-08-24T03:36:58.831941Z"
        },
        "id": "-kyvSyrk_gP7"
      },
      "source": [
        "# model.load_state_dict(torch.load('model_.pt'))\n",
        "model.load_state_dict(torch.load('model_best_2.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T05:39:39.687049Z",
          "iopub.status.busy": "2021-08-24T05:39:39.686591Z",
          "iopub.status.idle": "2021-08-24T05:39:39.693620Z",
          "shell.execute_reply": "2021-08-24T05:39:39.692737Z",
          "shell.execute_reply.started": "2021-08-24T05:39:39.687006Z"
        },
        "id": "K-aiH1HO_3fI"
      },
      "source": [
        "class TestMyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_dir,y_dir,augmentation = True):\n",
        "        super().__init__()\n",
        "        self.augmentation = augmentation\n",
        "        self.x_img = x_dir\n",
        "        self.y_img = y_dir\n",
        "     \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_img)\n",
        "    \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_img = self.x_img[idx]\n",
        "        y_img = self.y_img[idx]\n",
        "        # Read an image with OpenCV\n",
        "        x_img = dcm.dcmread(x_img)\n",
        "        y_img =  imread(y_img)\n",
        "\n",
        "        x_img=read_dicom(x_img,400,100)\n",
        "        x_img=np.transpose(x_img,(2,0,1))\n",
        "        x_img=x_img.astype(np.float32)\n",
        "        \n",
        "        y_img = resize(y_img, (512, 512))*255\n",
        "        color_im = np.zeros([512, 512, 2])\n",
        "        for i in range(1,3):\n",
        "            encode_ = to_binary(y_img, i*1.0, i*1.0) * 255\n",
        "            color_im[:, :, i-1] = encode_\n",
        "        color_im = np.transpose(color_im,(2,0,1))\n",
        "        # Data Augmentation\n",
        "        if self.augmentation:\n",
        "            img, mask = augment_imgs_and_masks(x_img, color_im, rot_factor, scale_factor, trans_factor, flip)\n",
        "\n",
        "        return x_img,mask,y_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T05:39:41.482456Z",
          "iopub.status.busy": "2021-08-24T05:39:41.482134Z",
          "iopub.status.idle": "2021-08-24T05:39:42.545908Z",
          "shell.execute_reply": "2021-08-24T05:39:42.544947Z",
          "shell.execute_reply.started": "2021-08-24T05:39:41.482426Z"
        },
        "id": "K3ukk_-U4V7-"
      },
      "source": [
        "# test_path=sorted(glob.glob( \"./test/DICOM/**/*.dcm\",recursive=True ))\n",
        "test_input_files = data_path[6301:].to_numpy()\n",
        "test_label_files = label_path[6301:].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T05:39:42.570321Z",
          "iopub.status.busy": "2021-08-24T05:39:42.570055Z",
          "iopub.status.idle": "2021-08-24T05:39:42.576653Z",
          "shell.execute_reply": "2021-08-24T05:39:42.575651Z",
          "shell.execute_reply.started": "2021-08-24T05:39:42.570296Z"
        },
        "id": "IuULlvWU4Hd-"
      },
      "source": [
        "test_dataset = TestMyDataset(test_input_files,test_label_files)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T05:39:43.626951Z",
          "iopub.status.busy": "2021-08-24T05:39:43.626570Z",
          "iopub.status.idle": "2021-08-24T05:39:44.078661Z",
          "shell.execute_reply": "2021-08-24T05:39:44.076770Z",
          "shell.execute_reply.started": "2021-08-24T05:39:43.626916Z"
        },
        "id": "j3_Ig2EjI22v"
      },
      "source": [
        "images,labels,a = next(iter(test_loader))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "plt.figure(figsize=(16,18))\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(images[0][0])\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(labels[0][0])\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(labels[0][1])\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(a[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-08-24T05:39:49.167982Z",
          "iopub.status.busy": "2021-08-24T05:39:49.167639Z",
          "iopub.status.idle": "2021-08-24T05:39:49.176616Z",
          "shell.execute_reply": "2021-08-24T05:39:49.175842Z",
          "shell.execute_reply.started": "2021-08-24T05:39:49.167950Z"
        },
        "id": "kvPA_DQiI22v"
      },
      "source": [
        "len(test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}